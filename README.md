# NY-2015-Street-Tree-Data
## О проекте
В проекте был использован набор данных "NY-2015-Street-Tree-Data" (https://www.kaggle.com/datasets/new-york-city/ny-2015-street-tree-census-tree-data) для обучения модел нейронной сети с целью классификации состояния деревьев по трём классам - 'Good', 'Fair', 'Poor' и двум классам - 'Good', 'Fair' + 'Poor'.

## Основные этапы проекта
 - Генерация обучающего датасета цифр размером 32х32 пикселя по двум шаблонам шрифтов цифр, используемых на кредитных картах ([datacreator](./src/datacreator.py)). Для увеличения вариативности датасета использовалась библиотека аугментации данных albumentations;
 - Подготовка скрипта, содержащего реализацию класса для загрузки данных для обучения ([dataset](./src/dataloader.py));
 - Подготовка скрипта, содержащего класс архитектуры модели, класс, реализующий обучение модели, и класс, выполняющий инференс ([model](./src/nnet.py));
 - Обучение модели на различных датасетах с последующим сохранением ([learning](./src/main_learning.py));
 - Функционал для предсказания модели ([inference](./src/main_infer.py).

## Краткое изложение проекта и выводы

### Датасет
 - Т.к. в свободном доступе находится небольшое количество изображений цифр с кредитных карт (например, https://www.kaggle.com/datasets/barbaravanaki/credit-card-number-images содержит всего 885 изображений, распределённых по десяти классам), было решено сгенерировать обучающий датасет искусственно.
 - Датасет генерировался на основе двух шаблонов шрифтов цифр, используемых на кредитных картах.
 - Сгенерированный датасет содержит 80000 обучающих изображений - по 4000 изображений для каждого из двух типов шрифтов для десяти классов цифр; 20000 валидационных изображений и 10000 тестовых.
 - Класс создания датасета предусматривает как простое размножение изображений цифр, так и их аугментацию - аффинный преобразования (масштабирование, повороты и т.д.), размытие и т.д.
 - 

### Модель
 - В задаче была использована модель свёрточной нейронной сети типа vgg. После трёх свёрточных каскадов, выделяющих признаки и содержащих по два свёрточных слоя с 32-мя фильтрами формы (3,3) и завершающихся слоем макспуллинга с размером маски (2,2), следуют два полносвязных слоя, ответственные за классификацию, после которых идут слои пакетной нормализации и дропаута.
 - Везде были использованы функции активации LeakyReLU, за исключением последнего, классификиционного слоя, где применялась функция активации SoftMax.
 - Функция потерь - CrossEntropyLoss, в данном случае мультиклассовая перекрёстная энтропия.
 - Оптимизатор - Adam, с коэффицентов обучения 1е-5 и параметром weight_decay, отвечающим за регуляризацию, равным 1e-3.
 - 

 - Так как данные представлены в табличной форме, то была выбрана самая простая архитектура полносвязной нейронной сети. Применять более сложные архитектуры (CNN, RNN и т.д.) не виделось возможным. Так же были включены слои пакетной нормализации и прореживания. 
 - Обучение проводилось на всех восьми датасетах, результаты сохранены в директории [models](./models)

### Метрики
 - Для валидации были использованы метрики accuracy и, в качестве эксперимента, precision, recall и f1_score. 

### Результаты и выводы
 - На всех несбаласированных датасетах, как в случае двух целевых классов, так и в случае трёх, сеть показала одинаковые результаты - точность около 81%. Однако, этот результат не является сколько-нибудь положительным по двум причинам: во-первых, эта точность совпадает с количеством меток класса 'Good' в несбалансированных выборках; во-вторых, метрика accuracy плохо работает для сильно несбалансированных выборок - модели достаточно каждый раз указывать метку преобладающего класса и значения метрики будут высоки. Здесь сработали оба этих фактора - на несбалансированных датасетах как в случае двух целевых классов, так и в случае трёх, модель всё время предсказывали значение, соответствующее классу 'Good'. Ниже приведены примеры графиков для метрики для несбалансированных датасетов

<img width="432" alt="acc_dists_2" src="./plots/acc_dists_2.png" />  <img width="432" alt="acc_dists_2" src="./plots/acc_dists_3.png" />

<img width="432" alt="acc_dists_2" src="./plots/acc_xyd_2.png" />  <img width="432" alt="acc_dists_2" src="./plots/acc_xyd_3.png" />

 - На сбалансированных датасетах сеть показала результаты несколько лучше, чем случайное угадывание: accuracy показало около 60% для датасета с расстояниями и около 57.5% для датасета с координатами и диаметрами для двух классов (около 52% постоянное предсказывание класса 'Good'), и 43.5% для датасета с расстояниями и около 41% для датасета с координатами и диаметрами для трёх классов (около 35% постоянное предсказывание класса 'Good'). Небольшой прирост точности связан со сбалансированность этих датасетов по классам. Ниже приведены примеры графиков для метрики для сбалансированных датасетов

<img width="432" alt="acc_dists_2_balanced" src="./plots/acc_dists_2_balanced.png" />  <img width="432" alt="acc_dists_2_balanced" src="./plots/acc_dists_3_balanced.png" />

<img width="432" alt="acc_dists_2_balanced" src="./plots/acc_xyd_2_balanced.png" />  <img width="432" alt="acc_dists_2_balanced" src="./plots/acc_xyd_3_balanced.png" />
 
 - Варьирование количества слоёв и нейронов слоях, а, также, использование разных функций активации не сказывается на улучшении качества модели.
 - Для эксперимента были использованы метрики precision, recall и f1_score, которые хорошо работают в таких случаях, однако их значения оказались на уровне 60%, что также является отрицательным результатом. Дальнейшее их использование на данном этапе выглядит нецелесообразным.
 
 - Для дальнейшего улучшения качества модели необходимо улучшать датасет. Во-первых попытаться сбалансировать его. На это указывает существенное улучшение качества модели по сравнению с её предсказаниями после обучения на несбалансированных датасетах. Во-вторых, увеличить количество и качество признаков. На первое может указывать то, что точность модели немного выше на датасете, содержащем расстояния в качестве признаков, существенно увеличивая т.о. их количество. На второе указывает, то что в самом датасете значения многих признаков одиноковые для разных деревьев и, более того, для разных классов. Также в датасете присутствуют признаки, которые вызывают сомнение во влиянии на состояние дерева, например, наличие на ветке висящих кроссовок.
 - Также рекомендуется параллельно поэкспериментировать с методами классического машинного обучения, напрмиер, с логистической регрессией для сравнения результатов с методами глубокого обучения для последующего вывода о целесообразности применения того или иного подхода.

### Использование
Проект предполагает несколько режимов использования:
 - Обучение сети. Запускается скриптом [learning](./src/main_learning.py) из IDE или командной строки.
Все параметры, необходимые для начала процесса обучения находятся в yaml-файле [parameters_learning](./src/paramters/parameters_learning.yaml), путь к которому считывается автоматически. Однако пользователь может изменить путь при помощи флага командной строки --par_dir. Содержимое файла с параметрами:
    - path_data_model - список путей к данным и директории, где должны находиться модели;
    - mode - выбор режима, в данном случае 'train';
    - batch_size - размер батчей;
    - output_size - количесво выходом модели (количество классов);
    - device - устройство, на котором будет проходить обучение;
    - EPOCHS - количество эпох обучения.

 - Предсказание обученной сети. Здесь реализованы две возможности:
    - Непосредственный запуск из директории проекта скрипта [infer_main](./src/infer_main.py). В это случае реализовано две возможности - выполнять предсказания по данным из тестового набора, либо по пользовательским дланным. Для этого в файле параметров, имеющем структуру
       - path_data_model - список путей к данным и директории, где должны находиться модели; 
       - mode - выбор режима, в данном случае 'test' или 'predict';
       - output_size: - количесво выходом модели (количество классов);
       - device: - устройство, на котором будет проходить обучение;
       - data_num - номер данных из тестового датасета, если mode='test'$
       - data - список значений, если mode='predict',
      необходимо указать соответствующие параметры и запустить скрипт в IDE или из командной строки.
    - Запуск на странице браузера при помощи FastAPI. Для этого необходимо запустить в командной строке скрипт [infer_API](./src/infer_API.py), затем скопировать полученный адрес и ввести его в браузере с добавлением /docs. На странице во вкладке predict ввести все необходимые данные.



